{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04aab648-5131-49e9-93b3-f5e034055a64",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Time Series Forecasting with AutoMLV2\n",
    "\n",
    "This notebook uses Amazon SageMaker Autopilot to train a time-series model and produce predictions against the trained model. At the top-level, customers provide a set of tabular historical data on S3 and make an API to train a model. Once the model has been trained, you can elect to produce prediction as a batch or via a real-time endpoint. As part of the training process, SageMaker Autopilot manages and runs multiple time series models concurrently. All of these models are combined into a single ensembled model which blends the candidate models in a ratio that minimizes forecast error. Customers are provided with metadata and models for the ensemble and all underlying candidate models too. SageMaker Autopilot orchestrates this entire process and provides several artifacts as a result.\n",
    "\n",
    "These artifacts include:\n",
    "\n",
    "- backtest (holdout) forecasts per base model over multiple time windows,\n",
    "- accuracy metrics per base model,\n",
    "- backtest results and accuracy metrics for the ensembled model,\n",
    "- a scaled explainability report displaying the importance of each covariate and static metadata feature.\n",
    "- all model artifacts are provided as well on S3, which can be registered or use for batch/real-time inference\n",
    "\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "This notebook has been run in Amazon SageMaker Studio. The space is configured with a `t3.medium`, with image `SageMaker Distribution 1.4` and kernel `Python 3 (ipykernel)`.\n",
    "\n",
    "![space-config.png](images/1-space-config.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062cf419-8559-4fcd-9aa5-cbce9f00348d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade pip boto3 botocore sagemaker --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a033f3-7a2e-4d8f-993a-3918220e3fad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SageMaker Python SDK Dependencies\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, image_uris, Model\n",
    "from sagemaker.automl.automlv2 import AutoMLV2, AutoMLTimeSeriesForecastingConfig, AutoMLDataChannel\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "# Local helper functions\n",
    "from config.filling_config import filling_config\n",
    "from pipeline.automlv2_inference_pipeline import run_inference_pipeline\n",
    "from utils.utils import copy_download_training_data, split_train_test\n",
    "\n",
    "# Other dependencies\n",
    "import boto3\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from time import gmtime, sleep, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3865d4de-2de5-42ca-aad0-fe3e8d1c8408",
   "metadata": {},
   "source": [
    "## Copy Data Between S3 Buckets \n",
    "\n",
    "We provide a sample set of data to accompany this notebook. You may use our synthetic dataset, or alter this notebook to accommodate your own data. As a note, the next cell will copy a file to your S3 bucket and prefix defined in the last cell. As an alternate, we provide a method to copy the file to your local disk too.\n",
    "\n",
    "IMPORTANT: When training a model, your input data can contain a mixture of covariate and static item metadata. Take care to create future-dated rows that extend to the end of your prediction horizon. In the future-dated rows, carry your static item metadata and expected covariate values. Future-dated target-value (y) should be empty. Please download the example synthetic file using the S3 copy command in the next cell. You can observe the data programmatically or in a text editor as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13313f03-5e6d-4f72-8031-cfab66b2c367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Modify the following default_bucket to use a bucket of your choosing\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'automlv2-time-series-data'\n",
    "\n",
    "# Configure SageMaker permissions\n",
    "try:\n",
    "    role = get_execution_role() \n",
    "except:\n",
    "    # if you're running the notebook outside SageMaker Studio, replace with Execution Role name\n",
    "    role = boto3.client(\"iam\").get_role(RoleName=\"YOUR-SAGEMAKER-EXECUTION-ROLE-NAME\")[\"Role\"].get(\"Arn\")\n",
    "\n",
    "# This is the client we will use to interact with SageMaker Autopilot\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e5501a-4e80-4468-bdf8-15cd23893a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_data_csv = copy_download_training_data(\n",
    "    source_bucket=\"amazon-forecast-samples\", \n",
    "    source_key=\"autopilot/synthetic-food-demand.csv\",\n",
    "    destination_bucket=bucket,\n",
    "    destination_prefix=prefix, \n",
    "    destination_suffix=\"/full-data/synthetic-food-demand.csv\", \n",
    "    download=True\n",
    ")                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fee25a-b633-475f-93ad-0cae67cbb043",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(full_data_csv)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f7f63e-2ceb-4c47-a260-18ed866999f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_train_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb577509-534d-4720-a6d4-a6f257e1cc4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "bucket_name = bucket\n",
    "folder_prefix = 'automlv2-time-series-data'\n",
    "\n",
    "s3_client.upload_file('data/train.csv', bucket, f\"{folder_prefix}/train/train.csv\")\n",
    "\n",
    "s3_client.upload_file('data/train.csv', bucket, f\"{folder_prefix}/batch_transform/input/batch-food-demand.csv\")\n",
    "\n",
    "s3_client.upload_file('data/test.csv', bucket, f\"{folder_prefix}/test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5020422e-46b1-4855-988b-fb8fe594f921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp_suffix = strftime(\"%Y%m%d-%H%M%S\", gmtime())\n",
    "auto_ml_job_name = \"ts-\" + timestamp_suffix\n",
    "print(\"AutoMLJobName: \" + auto_ml_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9fa318-c6b8-443b-b9d2-0a1a67ece74e",
   "metadata": {},
   "source": [
    "## Define our AutoML time series config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352af83-54cc-4595-86ef-396d21205508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_series_config = AutoMLTimeSeriesForecastingConfig(\n",
    "    forecast_frequency='W',  # The frequency of predictions in a forecast.\n",
    "    forecast_horizon=4,  # The number of time-steps that the model predicts.\n",
    "    forecast_quantiles=['p50','p60','p70','p80','p90'], # The quantiles used to train the model for forecasts at a specified quantile. \n",
    "    filling=filling_config,\n",
    "    item_identifier_attribute_name=\"product_code\",\n",
    "    target_attribute_name='unit_sales',\n",
    "    timestamp_attribute_name='timestamp',\n",
    "    grouping_attribute_names=['location_code']\n",
    ")\n",
    "\n",
    "train_uri = 's3://{}/{}/train/'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ef2976-243d-48ae-9680-b0a1d1cccd5a",
   "metadata": {},
   "source": [
    "### Configuration Highlights:\n",
    "\n",
    "`forecast_frequency`\n",
    "* Description: Specifies how often predictions should be made.<br>\n",
    "* Value 'W': Indicates that forecasts are expected on a weekly basis. The model will be trained to understand and predict data as a sequence of weekly observations.\n",
    "\n",
    "`forecast_horizon`\n",
    "* Description: Defines the number of future time-steps the model should predict.<br>\n",
    "* Value 4: The model will forecast four time-steps into the future. Given the weekly frequency, this means the model will predict the next four weeks of data from the last known data point.\n",
    "\n",
    "`forecast_quantiles`\n",
    "* Description: Specifies the quantiles at which to generate probabilistic forecasts.<br>\n",
    "* Values ['p50','p60','p70','p80','p90']: These quantiles represent the 50th, 60th, 70th, 80th, and 90th percentiles of the forecast distribution, providing a range of possible outcomes and capturing forecast uncertainty. For instance, the p50 quantile (median) might be used as a central forecast, while p90 provides a higher-end estimate, accounting for potential variability.\n",
    "\n",
    "`filling`\n",
    "* Description: Defines how missing data should be handled before training, specifying filling strategies for different scenarios and columns.<br>\n",
    "* Value filling_config: This should be a dictionary detailing how to fill missing values in your dataset, such as filling missing promotional data with zeros or specific columns with predefined values. This ensures the model has a complete dataset to learn from, improving its ability to make accurate forecasts.\n",
    "\n",
    "`item_identifier_attribute_name`\n",
    "* Description: Specifies the column that uniquely identifies each time series in the dataset.<br>\n",
    "Value \"product_code\": This setting indicates that each unique product code represents a distinct time series. The model will treat data for each product code as a separate forecasting problem.\n",
    "\n",
    "`target_attribute_name`\n",
    "* Description: The name of the column in your dataset that contains the values you want to predict.<br>\n",
    "Value 'unit_sales': Designates the unit_sales column as the target variable for forecasts, meaning the model will be trained to predict future sales figures.\n",
    "\n",
    "`timestamp_attribute_name`\n",
    "* Description: The name of the column indicating the time point for each observation.<br>\n",
    "Value 'timestamp': Specifies that the timestamp column contains the temporal information necessary for modeling the time series.\n",
    "\n",
    "`grouping_attribute_names`\n",
    "* Description: A list of column names that, in combination with the item identifier, can be used to create composite keys for forecasting.<br>\n",
    "Value ['location_code']: This setting means that forecasts will be generated for each combination of product_code and location_code. It allows the model to account for location-specific trends and patterns in sales data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f536fa4a-6620-4cf0-947f-9b354472804a",
   "metadata": {},
   "source": [
    "## Create an AutoMLV2 Job to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a2c4a4-83b6-4e12-8e5e-4654641d5f78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "automl_sm_job = AutoMLV2(\n",
    "    problem_config=time_series_config,\n",
    "    role=role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    base_job_name='time-series-forecasting-job',\n",
    "    output_path=f's3://{bucket}/{prefix}/output'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ca8e2c-2623-4bf3-ae3e-bf5aef559a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_sm_job.fit(\n",
    "    inputs=[AutoMLDataChannel(s3_data_type='S3Prefix', s3_uri=train_uri, channel_type='training')],\n",
    "    wait=True,\n",
    "    logs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9a7306-c28f-4b82-ba5e-4685a0f39672",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retrieve the best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5aed93-d327-4e8e-8f9a-ef70a92f30ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the best candidate(s) from the AutoML job\n",
    "\n",
    "# Option 1: Run if you've just fit your AutoML job\n",
    "best_candidate = automl_sm_job.best_candidate()\n",
    "\n",
    "# Option 2: Run if you know what job name you want to find the best candidate from \n",
    "# best_candidate = automl_sm_job.best_candidate(job_name='time-ser-2024-03-11-18-33-48-786')\n",
    "\n",
    "best_candidate_name = best_candidate['CandidateName']\n",
    "\n",
    "print('BestCandidateName:', best_candidate_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80bbabc-d217-45b6-9e29-1a094a99b86f",
   "metadata": {},
   "source": [
    "## Deploy the best model to a SageMaker Real-time endpoint\n",
    "\n",
    "If you want to perform real-time inference, review this section. If you want to perform batch processing, you may skip the real-time inference section and move to [Batch Predictions (Inference)](https://github.com/aws/amazon-sagemaker-examples/blob/7f1133ebc4e1fe28bcedbeca127c3b95be566d9d/autopilot/#batch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb2c88-dc00-424f-876f-4b8d4953f58f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = f\"ep-{best_candidate_name}-automl-ts\"\n",
    "\n",
    "automl_sm_model = automl_sm_job.create_model(name=best_candidate_name, candidate=best_candidate)\n",
    "\n",
    "predictor = automl_sm_model.deploy(initial_instance_count=1, endpoint_name=endpoint_name, instance_type='ml.m5.large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285362c",
   "metadata": {},
   "source": [
    "Now, we test the inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f51de4-a4b7-4219-bf1f-066d00d99a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A small sample file that corresponds to the sample training dataset and trained model schema\n",
    "!aws s3 cp s3://amazon-forecast-samples/autopilot/real-time-payload.csv data/real-time-payload.csv\n",
    "\n",
    "input_file = './data/real-time-payload.csv'\n",
    "f=open(input_file,'r')\n",
    "inference_data = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35188399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "realtime_predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "initial_args = {\n",
    "    \"EndpointName\": endpoint_name,\n",
    "    \"Body\": inference_data,\n",
    "    \"ContentType\": \"text/csv\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ce74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = realtime_predictor.predict(\n",
    "    data=inference_data,\n",
    "    initial_args=initial_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c7deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding the byte data to a string, assuming UTF-8 encoding\n",
    "decoded_data = response.decode('utf-8')\n",
    "\n",
    "output_file = 'data/real-time-prediction-output.csv'\n",
    "# Writing the decoded data to a CSV file\n",
    "with open(output_file, 'w', newline='') as file:\n",
    "    file.write(decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df1cf6-cb3a-4513-9d1c-a4e92b47f04c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(StringIO(decoded_data), sep=',')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28407579-8139-4c1c-8846-c05d5ad8cd7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy the best model to a SageMaker Asynchronous Endpoint\n",
    "\n",
    "Amazon SageMaker Asynchronous Inference is a capability in SageMaker that queues incoming requests and processes them asynchronously. This option is ideal for requests with large payload sizes (up to 1GB), long processing times (up to one hour), and near real-time latency requirements. Asynchronous Inference enables you to save on costs by autoscaling the instance count to zero when there are no requests to process, so you only pay when your endpoint is processing requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa29c99-db54-470f-b6aa-60e764b29ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the model artifacts\n",
    "async_image = best_candidate['InferenceContainerDefinitions']['CPU'][0]['Image']\n",
    "async_model_data = best_candidate['InferenceContainerDefinitions']['CPU'][0]['ModelDataUrl']\n",
    "async_env = best_candidate['InferenceContainerDefinitions']['CPU'][0]['Environment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ffc29-dfee-4672-b04b-b95108302d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "automl_sm_async_model = Model(image_uri=async_image, model_data=async_model_data, env=async_env, role=sagemaker.get_execution_role())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a3b0a9-1412-4bd2-b70d-67f0d15b44a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "\n",
    "endpoint_name_async = f\"ep-{best_candidate_name}-automl-ts-async\"\n",
    "\n",
    "# Deploy the model to the asynchronous endpoint\n",
    "async_predictor = automl_sm_async_model.deploy(\n",
    "    endpoint_name=endpoint_name_async,\n",
    "    instance_type=\"ml.m5.xlarge\", initial_instance_count=1,\n",
    "    serializer=sagemaker.serializers.CSVSerializer(), deserializer=sagemaker.deserializers.CSVDeserializer(),\n",
    "    async_inference_config=AsyncInferenceConfig(output_path=f\"s3://{bucket}/{prefix}/async_output/\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeddf3eb-a332-4c7c-aa94-3f49b680d931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_location = copy_download_training_data(\n",
    "    source_bucket=\"amazon-forecast-samples\", \n",
    "    source_key=\"autopilot/real-time-payload.csv\",\n",
    "    destination_prefix=prefix,\n",
    "    destination_bucket=bucket,\n",
    "    destination_suffix=\"/realtime-data/real-time-payload.csv\", \n",
    "    download=False\n",
    ")\n",
    "\n",
    "s3_input_location = f\"s3://{input_location}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4521f8-768b-4966-91cb-33db2d623055",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor_async import AsyncPredictor\n",
    "\n",
    "async_realtime_predictor = AsyncPredictor(\n",
    "    realtime_predictor\n",
    ")\n",
    "\n",
    "async_initial_args = {\n",
    "    \"EndpointName\": endpoint_name_async,\n",
    "    \"InputLocation\": s3_input_location,\n",
    "    \"InvocationTimeoutSeconds\": 3600\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ad4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "async_response = async_realtime_predictor.predict(\n",
    "    input_path=s3_input_location,\n",
    "    initial_args=async_initial_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2afe273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding the byte data to a string, assuming UTF-8 encoding\n",
    "async_decoded_data = async_response.decode('utf-8')\n",
    "\n",
    "async_output_file = 'data/async-real-time-prediction-output.csv'\n",
    "# Writing the decoded data to a CSV file\n",
    "with open(async_output_file, 'w', newline='') as file:\n",
    "    file.write(async_decoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(StringIO(async_decoded_data), sep=',')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fa7195-1d5a-46e9-b837-41cadaefb693",
   "metadata": {},
   "source": [
    "## Cleanup: Delete both endpoints\n",
    "\n",
    "Once you're done with the endpoints, you can delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b2501-af82-4074-a0e6-dabddf9079aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name_async)\n",
    "sagemaker_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47dfa0-c8e5-4487-83f9-6dc116e8c7bf",
   "metadata": {},
   "source": [
    "## MLOps with Amazon SageMaker Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1800c4",
   "metadata": {},
   "source": [
    "In this code block, we are initializing the AutoML pipeline for a time series forecasting job using SageMaker's `AutoMLV2` class. The `PipelineSession` object is used to manage the SageMaker session specifically for pipeline operations. The `AutoMLV2` object is configured with several parameters:\n",
    "\n",
    "- `problem_config` specifies the configuration for the time series problem, including aspects like forecast horizon, frequency, etc.\n",
    "\n",
    "- `role` is the AWS Identity and Access Management (IAM) role that SageMaker assumes to perform operations on your behalf.\n",
    "\n",
    "- `sagemaker_session` is the session object that `AutoMLV2` will use to interact with SageMaker services.\n",
    "\n",
    "- `base_job_name` provides a base name for the job, helping with organizing and tracking jobs in SageMaker.\n",
    "\n",
    "- `output_path` defines the S3 path where the output of the AutoML job, including models and artifacts, will be stored.\n",
    "\n",
    "This setup initiates the AutoML process, preparing it to automatically analyze the data, select algorithms, and train models best suited for the time series forecasting problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c3ad2e-a8a3-4141-b72f-4f865ff42740",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_session = PipelineSession()\n",
    "\n",
    "automl_pipeline_job = AutoMLV2(\n",
    "    problem_config=time_series_config,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    base_job_name='time-series-forecasting-job',\n",
    "    output_path=f's3://{bucket}/{prefix}/output'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b12eea3",
   "metadata": {},
   "source": [
    "This segment of the code is focused on creating a SageMaker model from the best candidate generated by the AutoML job and retrieving insights about the model:\n",
    "\n",
    "- `automl_pipeline_model` is created using the `create_model` method of the `AutoMLV2` object, which packages the best candidate model for deployment. This model is identified by `best_candidate_name` and originates from the `best_candidate` data structure.\n",
    "\n",
    "- `model_insights_report` and `model_explainability_report` are extracted from the `best_candidate`'s properties. These reports provide valuable insights into the model's performance and explainability, offering an in-depth understanding of how the model makes its predictions.\n",
    "\n",
    "These steps are crucial for model governance and interpretability, ensuring that the selected model is both effective and understandable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1207f9-c016-4a7e-bc60-f2eca32eff96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "automl_pipeline_model = automl_pipeline_job.create_model(name=best_candidate_name, candidate=best_candidate)\n",
    "\n",
    "model_insights_report = best_candidate['CandidateProperties']['CandidateArtifactLocations']['ModelInsights']\n",
    "\n",
    "model_explainability_report = best_candidate['CandidateProperties']['CandidateArtifactLocations']['Explainability']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b480603-04bd-4b5f-a58c-ebc0781dbc83",
   "metadata": {},
   "source": [
    "Now run through a (batch) inference pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b662c6a3-b5f1-40dc-94a6-b35da3319f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running the inference pipeline with model_insights_report = {model_insights_report}\")\n",
    "\n",
    "print(f\"Running the inference pipeline with model_explainability_report = {model_explainability_report}\")\n",
    "\n",
    "print(f\"Running the inference pipeline with model_name = {best_candidate_name}\")\n",
    "\n",
    "print(f\"Running the inference pipeline with model = {automl_pipeline_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372bacc2",
   "metadata": {},
   "source": [
    "In the final block, an inference pipeline is executed, and its progress is monitored:\n",
    "\n",
    "- `run_inference_pipeline` function is called with several parameters, including the session object, the AutoML model, model name, explainability report, and model insights report. This function is responsible for orchestrating the inference pipeline execution, which involves deploying the model and running inference tasks.\n",
    "\n",
    "- `describe()` method is called on the `inference_pipeline_execution` object to get a detailed description of the pipeline execution status.\n",
    "\n",
    "- `wait(delay=30, max_attempts=180)` is invoked to periodically check the status of the pipeline execution, with a 30-second delay between checks, up to a maximum of 1.5 hours. This ensures that the script waits for the inference to complete or fail before proceeding.\n",
    "\n",
    "- Finally, `list_steps()` method lists all the steps involved in the pipeline execution, providing visibility into the pipeline's components and their statuses.\n",
    "\n",
    "This comprehensive approach allows for a managed execution of the inference pipeline, ensuring that the deployed model is accurately making predictions and that the process is transparent and trackable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cdd381-b486-471d-b989-529ac0bc498b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_pipeline_execution = run_inference_pipeline(pipeline_session=PipelineSession(), automl_model=automl_pipeline_model, model_name=best_candidate_name, explainability=model_explainability_report, model_insights=model_insights_report)\n",
    "\n",
    "inference_pipeline_execution.describe()\n",
    "\n",
    "inference_pipeline_execution.wait(delay=30, max_attempts=180)  # max. wait: 1.5 hours\n",
    "\n",
    "inference_pipeline_execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f5b78-4570-46b5-afc3-a9c81360caa6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Batch Inference with SageMaker Batch Transform\n",
    "\n",
    "Amazon SageMaker Batch Transform is a high-performance and scalable service designed for running batch predictions on large datasets. It allows users to easily transform data and make predictions by deploying machine learning models without the need to manage any infrastructure. This service is particularly useful for scenarios where you need to process a large amount of data in a batch manner, such as for generating predictions from a trained model on a schedule or in response to specific events. Batch Transform automatically manages the computing resources required, scales them to match the volume of data, and efficiently processes the data in batches, making it a cost-effective solution for batch inference needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c989ca6f-365a-441a-8369-0d72ae1de514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a unique name for the transform job\n",
    "timestamp_suffix = strftime(\"%Y%m%d-%H%M%S\", gmtime())\n",
    "transform_job_name = f'{best_candidate_name}-' + timestamp_suffix\n",
    "print(\"BatchTransformJob: \" + transform_job_name)\n",
    "\n",
    "batch_s3_uri_input = f's3://{bucket}/{prefix}/batch_transform/input/batch-food-demand.csv'\n",
    "\n",
    "# Creating a transformer object\n",
    "transformer = Transformer(\n",
    "    model_name=best_candidate_name,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.12xlarge',\n",
    "    output_path=f's3://{bucket}/{prefix}/batch_transform/output/',\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    max_payload=0,  # in MB\n",
    "    strategy='SingleRecord',\n",
    "    assemble_with='Line',\n",
    ")\n",
    "\n",
    "# Start the transform job\n",
    "transformer.transform(\n",
    "    data=batch_s3_uri_input,\n",
    "    content_type='text/csv',\n",
    "    split_type='None',\n",
    "    job_name=transform_job_name\n",
    ")\n",
    "\n",
    "# Wait for the transform job to finish\n",
    "transformer.wait()\n",
    "\n",
    "# Optionally, to check the status after the job has been initiated\n",
    "describe_response = sagemaker_session.sagemaker_client.describe_transform_job(TransformJobName=transform_job_name)\n",
    "job_run_status = describe_response[\"TransformJobStatus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3672be-0e4a-4292-a71f-210bbb7eab98",
   "metadata": {},
   "source": [
    "Once completed, resulting prediction files are available at the URI shown in the prior cell, S3OutputPath. We use the API method describe_transform_job to complete this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba992a2-206b-4923-9aad-fa0d8358a6d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "# Initialize an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "# Get the object from S3\n",
    "\n",
    "object_key = '{}/batch_transform/output/batch-food-demand.csv.out'.format(prefix)\n",
    "obj = s3.get_object(Bucket=bucket, Key=object_key)\n",
    "\n",
    "# Read the data into a pandas DataFrame\n",
    "data = obj['Body'].read().decode('utf-8')\n",
    "df = pd.read_csv(StringIO(data))\n",
    "\n",
    "# Display the top of the DataFrame\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
